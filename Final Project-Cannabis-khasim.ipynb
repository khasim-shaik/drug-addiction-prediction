{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('drug_consumption.data',\n",
    "                 sep=',')\n",
    "data.columns=['ID','Age','Gender','Education','Country','Ethnicity','Nscore','Escore',\n",
    "             'Oscore','Ascore','Cscore','Impulsive','SS','Alcohol','Amphet','Amyl',\n",
    "             'Benzos','Caff','Cannabis','Choc','Coke','Crack','Ecstasy','Heroin',\n",
    "             'Ketamine','Legalh','LSD','Meth','Mushrooms','Nicotine','Semer','VSA']\n",
    "# drugs=drugs.replace('CL0',0)\n",
    "# drugs=drugs.replace('CL1',0)\n",
    "# drugs=drugs.replace('CL2',0)\n",
    "# drugs=drugs.replace('CL3',1)\n",
    "# drugs=drugs.replace('CL4',1)\n",
    "# drugs=drugs.replace('CL5',1)\n",
    "# drugs=drugs.replace('CL6',1)\n",
    "\n",
    "data=data.replace('CL0',1)\n",
    "data=data.replace('CL1',1)\n",
    "data=data.replace('CL2',1)\n",
    "data=data.replace('CL3',0)\n",
    "data=data.replace('CL4',0)\n",
    "data=data.replace('CL5',0)\n",
    "data=data.replace('CL6',0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split\n",
    "drugs=data.iloc[:,13:33]\n",
    "personality=data.iloc[:,2:13]\n",
    "d1=data.iloc[:,13:17]\n",
    "d2=data.iloc[:,19]\n",
    "d3=data.iloc[:,18]\n",
    "d4=data.iloc[:,20:33]\n",
    "legal=pd.concat([d1, d2], axis=1)\n",
    "illegal=pd.concat([d3,d4],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(drug):\n",
    "    a=illegal[drug].value_counts()\n",
    "    if illegal[illegal[drug]==0].shape[0]>illegal[illegal[drug]==1].shape[0]:\n",
    "        target=0\n",
    "        return target\n",
    "    else:\n",
    "        target=1\n",
    "        return target\n",
    "drug_name='LSD'\n",
    "target=get_target(drug_name)\n",
    "    \n",
    "major=(illegal.loc[illegal[drug_name]==target])\n",
    "minor=(illegal.loc[illegal[drug_name]==1-target])\n",
    "majorframe=major[drug_name]\n",
    "minorframe=minor[drug_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1504\n",
       "0    1504\n",
       "Name: LSD, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = majorframe\n",
    "df_minority = minorframe\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=illegal[illegal[drug_name]==target].shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Cannabis\n",
      "ROC AUC: 0.87 (+/- 0.03) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Cannabis\n",
      "ROC AUC: 0.81 (+/- 0.03) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Cannabis\n",
      "ROC AUC: 0.88 (+/- 0.03) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: KNN Classifier  with score of 0.8771212581553902 \n",
      "Cannabis\n",
      "Logistic Regression is the best model\n",
      "CV accuracy: 0.781 +/- 0.040\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Coke\n",
      "ROC AUC: 0.82 (+/- 0.03) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Coke\n",
      "ROC AUC: 0.77 (+/- 0.04) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Coke\n",
      "ROC AUC: 0.80 (+/- 0.03) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.8197642069884532 \n",
      "Coke\n",
      "KNN is the best model\n",
      "CV accuracy: 0.783 +/- 0.012\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Crack\n",
      "ROC AUC: 0.85 (+/- 0.08) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Crack\n",
      "ROC AUC: 0.78 (+/- 0.10) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Crack\n",
      "ROC AUC: 0.82 (+/- 0.07) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.85472149314669 \n",
      "Crack\n",
      "KNN is the best model\n",
      "CV accuracy: 0.958 +/- 0.004\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Ecstasy\n",
      "ROC AUC: 0.82 (+/- 0.03) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Ecstasy\n",
      "ROC AUC: 0.78 (+/- 0.04) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Ecstasy\n",
      "ROC AUC: 0.81 (+/- 0.04) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.8246816306438017 \n",
      "Ecstasy\n",
      "Logistic Regression is the best model\n",
      "CV accuracy: 0.750 +/- 0.016\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Heroin\n",
      "ROC AUC: 0.89 (+/- 0.03) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Heroin\n",
      "ROC AUC: 0.75 (+/- 0.03) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Heroin\n",
      "ROC AUC: 0.85 (+/- 0.03) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.885307937756797 \n",
      "Heroin\n",
      "KNN is the best model\n",
      "CV accuracy: 0.937 +/- 0.003\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Ketamine\n",
      "ROC AUC: 0.79 (+/- 0.04) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Ketamine\n",
      "ROC AUC: 0.70 (+/- 0.06) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Ketamine\n",
      "ROC AUC: 0.76 (+/- 0.07) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.7851846333202267 \n",
      "Ketamine\n",
      "Logistic Regression is the best model\n",
      "CV accuracy: 0.888 +/- 0.003\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Legalh\n",
      "ROC AUC: 0.84 (+/- 0.03) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Legalh\n",
      "ROC AUC: 0.79 (+/- 0.05) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Legalh\n",
      "ROC AUC: 0.84 (+/- 0.04) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.8440574990110404 \n",
      "Legalh\n",
      "Logistic Regression is the best model\n",
      "CV accuracy: 0.759 +/- 0.012\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " LSD\n",
      "ROC AUC: 0.85 (+/- 0.04) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " LSD\n",
      "ROC AUC: 0.77 (+/- 0.03) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " LSD\n",
      "ROC AUC: 0.86 (+/- 0.04) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: KNN Classifier  with score of 0.8579609919547027 \n",
      "LSD\n",
      "Decision Tree is the best model\n",
      "CV accuracy: 0.798 +/- 0.003\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Meth\n",
      "ROC AUC: 0.87 (+/- 0.02) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Meth\n",
      "ROC AUC: 0.78 (+/- 0.03) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Meth\n",
      "ROC AUC: 0.86 (+/- 0.02) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: Logistic Regression  with score of 0.8734390977988904 \n",
      "Meth\n",
      "Decision Tree is the best model\n",
      "CV accuracy: 0.830 +/- 0.002\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Mushrooms\n",
      "ROC AUC: 0.85 (+/- 0.02) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Mushrooms\n",
      "ROC AUC: 0.76 (+/- 0.03) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Mushrooms\n",
      "ROC AUC: 0.85 (+/- 0.02) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: KNN Classifier  with score of 0.85033116025075 \n",
      "Mushrooms\n",
      "Decision Tree is the best model\n",
      "CV accuracy: 0.769 +/- 0.002\n",
      "10-fold cross validation:\n",
      "\n",
      "\n",
      " For Drug \n",
      " Nicotine\n",
      "ROC AUC: 0.76 (+/- 0.04) [Logistic Regression]\n",
      "\n",
      " For Drug \n",
      " Nicotine\n",
      "ROC AUC: 0.63 (+/- 0.02) [Decision Tree]\n",
      "\n",
      " For Drug \n",
      " Nicotine\n",
      "ROC AUC: 0.77 (+/- 0.04) [KNN Classifier]\n",
      "AUC SCORE RESULTS\n",
      "\n",
      "The best model is: KNN Classifier  with score of 0.7704706757574271 \n",
      "Nicotine\n",
      "Decision Tree is the best model\n",
      "CV accuracy: 0.612 +/- 0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a31865523004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m                                  \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                  \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                  scoring='roc_auc')\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n For Drug \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrugs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    204\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    269\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#slicing the data\n",
    "X=pd.concat([personality,legal],axis=1)\n",
    "def kval(start,end):\n",
    "    ks=list()\n",
    "    for i in range(start,end):\n",
    "        if i%2!=0:\n",
    "            ks.append(i)\n",
    "    return ks\n",
    "ks=kval(40,50)\n",
    "\n",
    "for drugs in illegal:\n",
    "    y=illegal[drugs]\n",
    "#stratify: cuz of the unbalanced data set: there are more class 1 than class 0. so we include more class 1 in both the test data and training set as well.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train_std = sc.transform(X_train)\n",
    "    X_test_std = sc.transform(X_test)\n",
    "\n",
    "    gs_knn = GridSearchCV(estimator=neighbors.KNeighborsClassifier(p=2, \n",
    "                               metric='minkowski'),\n",
    "                      param_grid=[{'n_neighbors': ks,'weights':['uniform','distance']}],\n",
    "                      scoring='recall',\n",
    "                      cv=10)\n",
    "\n",
    "    gs_knn = gs_knn.fit(X_train_std, y_train)          \n",
    "\n",
    "    knn_params=gs_knn.best_params_\n",
    "\n",
    "    \n",
    "    # Choosing depth of the tree AND splitting criterion AND min_samples_leaf AND min_samples_split\n",
    "    gs_dt2 = GridSearchCV(estimator=DecisionTreeClassifier(random_state=0),\n",
    "                      param_grid=[{'max_depth': [1, 2, 3, 4, 5, 6, 7, None], 'criterion':['gini','entropy'], \n",
    "                                  'min_samples_leaf':[1,2,3,4,5],\n",
    "                                  'min_samples_split':[2,3,4,5]}],\n",
    "                      scoring='recall',\n",
    "                      cv=10,\n",
    "                      n_jobs=4)\n",
    "\n",
    "    gs_dt2 = gs_dt2.fit(X_train,y_train)\n",
    "\n",
    "    dt_params=gs_dt2.best_params_\n",
    "\n",
    "    gs_lr2 = GridSearchCV(estimator=LogisticRegression(random_state=0),\n",
    "                      param_grid=[{'C': [ 0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000, 1000000, 10000000],\n",
    "                                 'penalty':['l1','l2']}],\n",
    "                      scoring='recall',\n",
    "                      cv=10)\n",
    "\n",
    "    gs_lr2 = gs_lr2.fit(X_train,y_train)\n",
    "#     print(gs_lr2.best_score_)\n",
    "    lr_params=gs_lr2.best_params_\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    \n",
    "####################################################################################################################\n",
    "##############################       AUC SCORE CALCULATION       ###################################################\n",
    "\n",
    "\n",
    "\n",
    "    # Logistic Regression Classifier\n",
    "    clf1 = LogisticRegression(penalty='l2', \n",
    "                              C=lr_params['C'],\n",
    "                              random_state=1)\n",
    "\n",
    "    # Decision Tree Classifier\n",
    "    clf2 = DecisionTreeClassifier(max_depth=dt_params['max_depth'],\n",
    "                                  criterion=dt_params['criterion'],\n",
    "                                  random_state=0)\n",
    "\n",
    "\n",
    "    # kNN Classifier\n",
    "    clf3 = neighbors.KNeighborsClassifier(n_neighbors=knn_params['n_neighbors'],\n",
    "                                weights=knn_params['weights'],\n",
    "                                p=2,\n",
    "                                metric='minkowski')\n",
    "\n",
    "    auc_scores=[0,0,0]\n",
    "    i=0\n",
    "    clf_labels=['Logistic Regression','Decision Tree','KNN Classifier']\n",
    "    print('10-fold cross validation:\\n')\n",
    "    for clf, label in zip([clf1, clf2,clf3], clf_labels): #For all classifiers \n",
    "        scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
    "                                 X=X_train,\n",
    "                                 y=y_train,\n",
    "                                 cv=10,\n",
    "                                 scoring='roc_auc')\n",
    "        print(\"\\n For Drug \\n\",drugs)\n",
    "        print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
    "              % (scores.mean(), scores.std(), label))\n",
    "        auc_scores[i]=scores.mean()\n",
    "        i+=1\n",
    "    print(\"AUC SCORE RESULTS\\n\")\n",
    "    #print(auc_scores)\n",
    "    print(\"The best model is: {0}  with score of {1} \".format(clf_labels[auc_scores.index(max(auc_scores))],max(auc_scores)))\n",
    "#     if auc_scores.index(max(auc_scores))==0:\n",
    "#         print(\"Best model is\", clf_labels[0])\n",
    "#     if auc_scores.index(max(auc_scores))==1:\n",
    "#         print(\"Best model is\", clf_labels[1])\n",
    "#     if auc_scores.index(max(auc_scores))==2:\n",
    "#         print(\"Best model is\", clf_labels[2])    \n",
    "\n",
    "    \n",
    "    knnscores=cross_val_score(gs_knn, X_train, y_train, \n",
    "                             scoring='accuracy', cv=10)\n",
    "    print(drugs)\n",
    "    #print('CV accuracy: %.3f +/- %.3f' % (np.mean(knnscores),\n",
    "#                                           np.std(knnscores)))\n",
    "\n",
    "\n",
    "    dtscores=cross_val_score(gs_dt2, X_train, y_train, \n",
    "                             scoring='accuracy', cv=10)\n",
    "    #print('CV accuracy: %.3f +/- %.3f' % (np.mean(dtscores),\n",
    "#                                           np.std(dtscores)))\n",
    "\n",
    "\n",
    "    lrscores=cross_val_score(gs_lr2, X_train, y_train, \n",
    "                             scoring='accuracy', cv=10)\n",
    "    #print('CV accuracy: %.3f +/- %.3f' % (np.mean(lrscores),\n",
    "#                                           np.std(lrscores)))\n",
    "    scores=[np.mean(knnscores)+np.std(knnscores),np.mean(dtscores)+np.std(dtscores),np.mean(lrscores)+np.std(lrscores)]\n",
    "    if scores.index(min(scores))==0:\n",
    "        print(\"KNN is the best model\\nCV accuracy: %.3f +/- %.3f\"% (np.mean(knnscores),\n",
    "                                          np.std(knnscores)))\n",
    "    elif scores.index(min(scores))==1:\n",
    "        print(\"Decision Tree is the best model\\nCV accuracy: %.3f +/- %.3f\"% (np.mean(dtscores),\n",
    "                                          np.std(dtscores)))\n",
    "    elif scores.index(min(scores))==2:\n",
    "        print(\"Logistic Regression is the best model\\nCV accuracy: %.3f +/- %.3f\"% (np.mean(lrscores),\n",
    "                                          np.std(lrscores)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "clf1 = LogisticRegression(penalty='l2', \n",
    "                          C=0.01,\n",
    "                          random_state=1)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,\n",
    "                              criterion='entropy',\n",
    "                              random_state=0)\n",
    "\n",
    "# kNN Classifier\n",
    "clf3 = KNeighborsClassifier(n_neighbors=51,\n",
    "                            p=2,\n",
    "                            metric='minkowski')\n",
    "\n",
    "# Label the classifiers\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN']\n",
    "all_clf = [clf1, clf2, clf3]\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([clf1, clf2, clf3], clf_labels): #For all classifiers \n",
    "    scores = cross_val_score(estimator=clf,  #Estimate AUC based on cross validation\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" #Print peformance statistics based on cross-validation\n",
    "          % (scores.mean(), scores.std(), label))\n",
    "\n",
    "colors = [ 'orange', 'blue', 'green']      #Colors for visualization\n",
    "linestyles = [':', '--', '-.', '-']        #Line styles for visualization\n",
    "for clf, label, clr, ls in zip(all_clf,\n",
    "               clf_labels, colors, linestyles):\n",
    "\n",
    "    # assuming the label of the positive class is 1 and data is normalized\n",
    "    y_pred = clf.fit(X_train,\n",
    "                     y_train).predict_proba(X_test)[:, 1] # Make predictions based on the classifiers\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test, # Build ROC curve\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)                # Compute Area Under the Curve (AUC) \n",
    "    plt.plot(fpr, tpr,                         # Plot ROC Curve and create label with AUC values\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.2f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')    # Where to place the legend\n",
    "plt.plot([0, 1], [0, 1], # Visualize random classifier\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])   #limits for x axis\n",
    "plt.ylim([-0.1, 1.1])   #limits for y axis\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "\n",
    "#plt.savefig('ROC_all_classifiers', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
